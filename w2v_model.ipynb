{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader\n",
    "import os\n",
    "from text_writer import *\n",
    "import pickle\n",
    "from w2v_functions import *\n",
    "import selection\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Google model\n",
    "f = open('mymodel.pkl', 'rb')\n",
    "google_model = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Wiki model\n",
    "wiki_model = Word2Vec.load('wiki_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new lists of words for the analysis\n",
    "\n",
    "list_E = ['environment', 'sustainability', 'climate', 'renewable', 'emission', 'pollution', 'recycle']\n",
    "\n",
    "list_S = ['social', 'disabled', 'health', 'discrimination', 'equality', 'community', 'diversity']\n",
    "\n",
    "list_G = ['governance', 'audit', 'leadership', 'compensation', 'transparency', 'vote', 'stakeholder']\n",
    "\n",
    "#add lists to a dictionary\n",
    "ESG_dict = {'Environmental': list_E, 'Social': list_S, 'Governance': list_G}\n",
    "topic_names = ['Environmental', 'Social', 'Governance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data as .txt\n",
    "\n",
    "#Choose type of data\n",
    "types = ['10-K', 'DEF 14A']\n",
    "#Choose Companies\n",
    "pa = os.getcwd().replace('\\\\', '/') +'/Top 40'\n",
    "print(os.path.exists(pa))\n",
    "tickers, years_for_each = selection.find_good(pa)\n",
    "tickers.append('WFC')\n",
    "tickers.append('BLK')\n",
    "#print(years_for_each)\n",
    "print(tickers)\n",
    "\n",
    "#Choose number of years\n",
    "nb = 10\n",
    "\n",
    "Tech = ['AAPL','MSFT','NVDA','ADBE','INTC','ORCL','QCOM']\n",
    "Telecom = ['VZ','CSCO','CMCSA','NFLX','TMUS']\n",
    "Banking = ['JPM','BAC','BLK','WFC']\n",
    "Retail = ['AMZN','WMT','NKE','KO']\n",
    "Health = ['UNH','ABT','MRK','PFE','TMO']\n",
    "sect = [Tech, Telecom, Banking, Retail, Health]\n",
    "\n",
    "#import data\n",
    "#import_data(nb, tickers, types, First=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select stopwords\n",
    "nonotext = open(os.getcwd().replace(\"\\\\\",\"/\") +\"/nonosquare.txt\",\"r\",encoding='utf-8')\n",
    "nonolist = nonotext.readlines()[0].split(\" \")\n",
    "\n",
    "#select sub-set of data\n",
    "tickerselect = ['NFLX']\n",
    "types = ['10-K', 'DEF 14A']\n",
    "print(tickerselect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute scores using w2v\n",
    "models = [wiki_model.wv]\n",
    "model_names = ['Wiki Model']\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    #Compute scores for each topic (each company, each year)\n",
    "    for topic, name in zip(ESG_dict.keys(), topic_names):\n",
    "        topic_list = ESG_dict[topic]\n",
    "        \n",
    "        for tick in tickerselect:\n",
    "            \n",
    "            #compute score for 10K\n",
    "            score_10K = score_w2v(model, topic_list, tick, \"10-K\", nonolist)\n",
    "            #compute score for Proxy Stat.\n",
    "            score_proxy = score_w2v(model, topic_list, tick, \"DEF 14A\", nonolist)\n",
    "            #compute weighted mean between scores\n",
    "            merger = merge_w2v(score_10K,score_proxy,wP=0.5,wK=0.5)\n",
    "            #plot scores\n",
    "            X,Y = plotting(merger)\n",
    "            plt.plot(X,Y,label = tick)\n",
    "            \n",
    "        plt.legend()\n",
    "        plt.title(name+' '+'('+model_name+')')  \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = os.getcwd().replace('\\\\', '/') + '/score_files_w2v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = wiki_model.wv\n",
    "\n",
    "for tick in tickers:\n",
    "    if os.path.exists(score_path + '/' + tick + '.txt'):\n",
    "        continue\n",
    "    else:\n",
    "        print(tick)\n",
    "        file_name = score_path + '/' + tick + '.txt'\n",
    "        score_tick = pd.DataFrame()\n",
    "        index = None\n",
    "        for topic, topic_name in zip(ESG_dict.keys(), topic_names):\n",
    "            topic_list = ESG_dict[topic]\n",
    "            score_10K = score_w2v(model, topic_list, tick, \"10-K\", nonolist)\n",
    "            score_proxy = score_w2v(model, topic_list, tick, \"DEF 14A\", nonolist)\n",
    "            merger = merge_w2v(score_10K,score_proxy,wP=0.5,wK=0.5)\n",
    "            score_tick[topic_name] = [val for val in merger.values()]\n",
    "            index = [key[-2:] for key in merger.keys()]\n",
    "\n",
    "        score_tick.index.name = 'Year'\n",
    "        score_tick.index = index   \n",
    "        new_text_file = open(file_name, \"w\", encoding = 'utf-8') \n",
    "        new_text_file.write(score_tick.to_string()) \n",
    "        new_text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}